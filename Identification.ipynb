{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import *\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEPATH = \"save/\"\n",
    "SPLIT_RATE = 0.9\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "SAVE_EVERY = 15\n",
    "DEV_EVERY = 15\n",
    "LOG_EVERY = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(y_true, y_pred, name):\n",
    "    target_names = ['A',\n",
    "                    'B',\n",
    "                    'C',\n",
    "                    'D',\n",
    "                    'E',\n",
    "                    'F']\n",
    "    clf_cm = confusion_matrix(y_true, y_pred)\n",
    "    clf_report = classification_report(y_true, y_pred, digits=4, target_names=target_names, output_dict=True)\n",
    "    clf_report2 = classification_report(y_true, y_pred, digits=4,target_names=target_names)\n",
    "    print(clf_report2)\n",
    "\n",
    "    f, ax= plt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :-3].T, \n",
    "                annot=True, cmap=\"Blues_r\", fmt=\".4f\")\n",
    "    ax.set_title(\"Classification Report\")\n",
    "    f.tight_layout()\n",
    "    if os.path.isdir(\"plots/\"):\n",
    "        plt.savefig(\"plots/\"+name+time.strftime('%H_%M_%S')+\"_classification_report.jpg\")\n",
    "    else:\n",
    "        os.mkdir(\"plots/\")\n",
    "        plt.savefig(\"plots/\"+name+time.strftime('%H_%M_%S')+\"_classification_report.jpg\")\n",
    "    f.clf()\n",
    "\n",
    "    f, ax= plt.subplots(figsize=(5,5))\n",
    "    #4.23及以前的图横轴True，纵轴Prediction\n",
    "    sns.heatmap(pd.DataFrame(clf_cm, index=target_names, columns=target_names).T, \n",
    "                    annot=True, cmap=\"BuGn\", fmt=\"d\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    f.tight_layout()\n",
    "    plt.savefig(\"plots/\"+name+time.strftime('%H_%M_%S')+\"_confusion_matrix.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class Basicblock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(Basicblock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.9)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.9)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, input):\n",
    "        residual = input\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "#         x = self.drop1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "#         x = self.drop2(x)\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "    def forward(self, input):\n",
    "        residual = input\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, block, num_layer, n_classes=6, input_channels=1, name=\"resnet18\"):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=0.9)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, num_layer[0])\n",
    "        self.layer2 = self._make_layer(block, 128, num_layer[1], 2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_layer[2], 2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_layer[3], 2)\n",
    "        self.conv2 = nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(512, momentum=0.9)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=9, stride=1)\n",
    "        self.fc1 = nn.Linear(9*512, n_classes)\n",
    "#         self.fc2 = nn.Linear(512, n_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.name = name\n",
    "        self.drop = nn.Dropout()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_block, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels*block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels*block.expansion, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*block.expansion, momentum=0.9)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        \n",
    "        self.in_channels = out_channels*block.expansion\n",
    "        for _ in range(1, num_block):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu(x)\n",
    "#         print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "#         x = self.drop(x)\n",
    "#         x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def _class_name(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Resnet(Basicblock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Resnet(Basicblock, [3, 4, 6, 3], name=\"resnet34\", **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "# def resnet50(pretrained=False, **kwargs):\n",
    "#     \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     model = Resnet(Bottleneck, [3, 4, 6, 3], name=\"resnet50\", **kwargs)\n",
    "#     if pretrained:\n",
    "#         # model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "#         model_path = './initmodel/resnet50_v2.pth'\n",
    "#         model.load_state_dict(torch.load(model_path), strict=False)\n",
    "#     return model\n",
    "\n",
    "# def resnet101(pretrained=False, **kwargs):\n",
    "#     \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     model = Resnet(Bottleneck, [3, 4, 23, 3], name=\"resnet101\", **kwargs)\n",
    "#     if pretrained:\n",
    "#         # model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "#         model_path = './initmodel/resnet101_v2.pth'\n",
    "#         model.load_state_dict(torch.load(model_path), strict=False)\n",
    "#     return model\n",
    "\n",
    "# def resnet152(pretrained=False, **kwargs):\n",
    "#     \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "#     Args:\n",
    "#         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "#     \"\"\"\n",
    "#     model = Resnet(Bottleneck, [3, 8, 36, 3], name=\"resnet152\", **kwargs)\n",
    "#     if pretrained:\n",
    "#         # model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "#         model_path = './initmodel/resnet152_v2.pth'\n",
    "#         model.load_state_dict(torch.load(model_path), strict=False)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block of layers: Conv --> BatchNorm --> ReLU --> Pool\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pool_mode='max'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, momentum = 0.9)\n",
    "        self.relu = nn.ReLU()\n",
    "        if pool_mode == \"max\":\n",
    "            self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        else:\n",
    "            self.pool = nn.AvgPool2d(3, stride=1)\n",
    "            \n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "#         x = self.drop(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self, n_classes=6, input_channels=1):\n",
    "        super(DeepNet, self).__init__()\n",
    "        self.convb1 = ConvBlock(input_channels, 64, 'max')\n",
    "        self.convb2 = ConvBlock(64, 64, 'max')\n",
    "        self.convb3 = ConvBlock(64, 128, 'max')\n",
    "        self.convb4 = ConvBlock(128, 128, 'avg')\n",
    "#         self.convb5 = ConvBlock(128, 256, 'max')\n",
    "#         self.convb6 = ConvBlock(256, 256, 'avg')\n",
    "        self.fc1 = nn.Linear(6272, 512)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, n_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def _class_name(self):\n",
    "        return \"DeepNet\"\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.convb1(input)\n",
    "        x = self.convb2(x)\n",
    "        x = self.convb3(x)\n",
    "        x = self.convb4(x)\n",
    "#         x = self.convb5(x)\n",
    "#         x = self.convb6(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DealDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.len = x_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "def data_loader(data_X, data_y):\n",
    "    data = DealDataset(data_X, data_y)\n",
    "    size = data.len\n",
    "    loader = DataLoader(dataset=data,           \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=True,\n",
    "                    num_workers=2)\n",
    "    return loader\n",
    "\n",
    "def checkpoint(net, save_path, acc, loss, iterations):\n",
    "    snapshot_prefix = os.path.join(save_path, 'snapshot_' + net._class_name())\n",
    "    snapshot_path = snapshot_prefix + '_acc_{:.2f}_loss_{:.4f}_iter_{}_model.pt'.format(acc, loss, iterations)\n",
    "    torch.save(net, snapshot_path)\n",
    "    for f in glob.glob(snapshot_prefix + '*'):\n",
    "        if f != snapshot_path:\n",
    "            os.remove(f)\n",
    "\n",
    "def train(optimizer, criterion, net, device, epoches, save_path=SAVEPATH):\n",
    "    iterations = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    best_dev_acc = -1; best_snapshot_path = ''\n",
    "    header = '  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy'\n",
    "    dev_log_template = ' '.join('{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.1f}%,{:>7.4f},{:8.4f},{:12.4f}%,{:12.4f}%'.split(','))\n",
    "    log_template = ' '.join('{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f} {:>7.1f}%,{:>7.4f},{},{:12.4f}%,{}'.split(','))\n",
    "    \n",
    "    if os.path.isdir(save_path) == False:\n",
    "        os.makedirs(save_path)\n",
    "    print(header)\n",
    "\n",
    "    train_loader = data_loader(np.load(\"X_train_p.npy\"), np.load(\"y_train_p.npy\"))\n",
    "    dev_loader = data_loader(np.load(\"X_test_p.npy\"), np.load(\"y_test_p.npy\"))\n",
    "    \n",
    "    records = {'acc':[],'dev_acc':[], 'loss':[], 'dev_loss':[]}\n",
    "\n",
    "    for epoch in range(epoches):  # loop over the dataset multiple times\n",
    "        correct, total, print_loss, n= 0, 0, 0, 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            iterations += 1\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs.float()) \n",
    "            \n",
    "            total += labels.size(0)\n",
    "            labels = labels.argmax(dim=1)\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            print_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "        \n",
    "            # compute accuracy \n",
    "            acc = correct / total * 100\n",
    "        \n",
    "            # checkpoint model periodically\n",
    "            if iterations % SAVE_EVERY == 0:\n",
    "                checkpoint(net, save_path, acc, print_loss/n, iterations)\n",
    "            \n",
    "            # validation model periodically\n",
    "            if iterations % DEV_EVERY == 0:\n",
    "                # calculate accuracy on validation set\n",
    "                dev_correct, dev_total, dev_loss , m = 0, 0, 0, 0\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    for dev_batch_idx, dev_batch in enumerate(dev_loader, 0):\n",
    "                        signals, labels = dev_batch\n",
    "                        signals = signals.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        \n",
    "                        predicts = net(signals.float())\n",
    "                        labels = labels.argmax(dim=1)\n",
    "                        dev_loss += criterion(predicts, labels).item()\n",
    "                        dev_correct += (torch.max(predicts, 1)[1].view(-1) == labels).sum().item()\n",
    "                        dev_total += labels.size(0)\n",
    "                        m += 1\n",
    "                dev_acc = 100. * dev_correct / dev_total\n",
    "\n",
    "                print(dev_log_template.format(time.time()-start,\n",
    "                    epoch, iterations, 1+i, len(train_loader),\n",
    "                    100. * (1+i) / len(train_loader), print_loss/n, dev_loss/m, acc, dev_acc))\n",
    "                \n",
    "                records['acc'].append(acc)\n",
    "                records['dev_acc'].append(dev_acc)\n",
    "                records['loss'].append(print_loss/n)\n",
    "                records['dev_loss'].append(dev_loss/m)\n",
    "\n",
    "                # update best valiation set accuracy\n",
    "                if dev_acc >= best_dev_acc:\n",
    "\n",
    "                    # found a model with better validation set accuracy\n",
    "\n",
    "                    best_dev_acc = dev_acc\n",
    "                    snapshot_prefix = os.path.join(save_path, 'best_snapshot_' + net._class_name())\n",
    "                    best_snapshot_path = snapshot_prefix + '_devacc_{:.2f}_devloss_{:.4f}__iter_{}_model.pt'.format(dev_acc, dev_loss/m, iterations)\n",
    "\n",
    "                    # save model, delete previous 'best_snapshot' files\n",
    "                    torch.save(net, best_snapshot_path)\n",
    "                    for f in glob.glob(snapshot_prefix + '*'):\n",
    "                        if f != best_snapshot_path:\n",
    "                            os.remove(f)\n",
    "                net.train()\n",
    "\n",
    "            elif iterations % LOG_EVERY == 0:\n",
    "                # print progress message\n",
    "                print(log_template.format(time.time()-start,\n",
    "                    epoch, iterations, 1+i, len(train_loader),\n",
    "                    100. * (1+i) / len(train_loader), print_loss/n, ' '*8, acc, ' '*12))\n",
    "            n += 1\n",
    "    print('Finished Training')\n",
    "    return net, best_snapshot_path, records\n",
    "\n",
    "def test(net, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    test_loader = data_loader(np.load(\"X_test_p.npy\"), np.load(\"y_test_p.npy\"))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            signals, labels = data\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.argmax(dim=1)\n",
    "            for i in labels.view(-1):\n",
    "                y_true.append(i.view(-1).tolist())\n",
    "            \n",
    "            outputs = net(signals.float())\n",
    "            predicted = outputs.data.argmax(dim=1)\n",
    "            for i in predicted.view(-1) :\n",
    "                y_pred.append(i.view(-1).tolist())\n",
    "            \n",
    "            labels = labels.view(-1)\n",
    "            correct += (predicted.view(-1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    acc = 100 * correct / total\n",
    "    print(total,correct)\n",
    "    print('Accuracy: %.2f %%' % acc)\n",
    "    return acc, np.ravel(y_true), np.ravel(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU for training\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "     8     0        15    15/15      100.0%  1.9560   1.7213      18.9189%      26.3158%\n",
      "    16     1        30    15/15      100.0%  1.8983   1.7063      25.6757%      31.5789%\n",
      "    24     2        45    15/15      100.0%  1.8351   1.7574      32.4324%      21.0526%\n",
      "    31     3        60    15/15      100.0%  1.7469   1.5594      44.5946%      47.3684%\n",
      "    39     4        75    15/15      100.0%  1.7012   1.5418      47.2973%      52.6316%\n",
      "    47     5        90    15/15      100.0%  1.5774   1.4972      60.8108%      57.8947%\n",
      "    55     6       105    15/15      100.0%  1.5328   1.5445      70.2703%      52.6316%\n",
      "    62     7       120    15/15      100.0%  1.4993   1.4089      68.9189%      63.1579%\n",
      "    71     8       135    15/15      100.0%  1.4543   1.4478      72.9730%      57.8947%\n",
      "    78     9       150    15/15      100.0%  1.3690   1.3883      81.0811%      63.1579%\n",
      "    86    10       165    15/15      100.0%  1.3463   1.3895      86.4865%      63.1579%\n",
      "    94    11       180    15/15      100.0%  1.3110   1.3263      86.4865%      68.4211%\n",
      "   102    12       195    15/15      100.0%  1.2982   1.3828      86.4865%      68.4211%\n",
      "   111    13       210    15/15      100.0%  1.2675   1.2876      91.8919%      84.2105%\n",
      "   119    14       225    15/15      100.0%  1.3451   1.5121      83.7838%      47.3684%\n",
      "   126    15       240    15/15      100.0%  1.2475   1.3668      90.5405%      73.6842%\n",
      "   133    16       255    15/15      100.0%  1.2537   1.3864      89.1892%      68.4211%\n",
      "   140    17       270    15/15      100.0%  1.2082   1.4051      95.9459%      57.8947%\n",
      "   147    18       285    15/15      100.0%  1.2542   1.4933      91.8919%      52.6316%\n",
      "   154    19       300    15/15      100.0%  1.2145   1.3309      95.9459%      73.6842%\n",
      "   161    20       315    15/15      100.0%  1.1738   1.3304      98.6486%      78.9474%\n",
      "   169    21       330    15/15      100.0%  1.1434   1.3936     100.0000%      73.6842%\n",
      "   176    22       345    15/15      100.0%  1.1473   1.3093      98.6486%      68.4211%\n",
      "   183    23       360    15/15      100.0%  1.1402   1.3929     100.0000%      63.1579%\n",
      "   190    24       375    15/15      100.0%  1.1695   1.3520      97.2973%      68.4211%\n",
      "   197    25       390    15/15      100.0%  1.1557   1.4277      97.2973%      63.1579%\n",
      "   205    26       405    15/15      100.0%  1.1858   1.4711      95.9459%      57.8947%\n",
      "   212    27       420    15/15      100.0%  1.1289   1.4055     100.0000%      68.4211%\n",
      "   220    28       435    15/15      100.0%  1.1622   1.4193      97.2973%      68.4211%\n",
      "   227    29       450    15/15      100.0%  1.1591   1.5542      97.2973%      52.6316%\n",
      "Finished Training\n",
      "19 16\n",
      "Accuracy: 84.21 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     1.0000    0.6667    0.8000         3\n",
      "           B     1.0000    1.0000    1.0000         4\n",
      "           C     1.0000    0.6667    0.8000         3\n",
      "           D     1.0000    0.6667    0.8000         3\n",
      "           E     0.6000    1.0000    0.7500         3\n",
      "           F     0.7500    1.0000    0.8571         3\n",
      "\n",
      "    accuracy                         0.8421        19\n",
      "   macro avg     0.8917    0.8333    0.8345        19\n",
      "weighted avg     0.8974    0.8421    0.8432        19\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_device(1)\n",
    "        device = torch.device('cuda:{}'.format(1))\n",
    "        print(\"Using GPU for training\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    net = resnet34().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.00005, weight_decay=1e-8)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net, fp, records = train(optimizer, criterion, net, device, 30)\n",
    "    np.save(\"records_resnet34_p\", records)\n",
    "#     net = torch.load(\"save/best_snapshot_DeepNet_devacc_63.16_devloss_1.5753__iter_225_model.pt\")\n",
    "    net = torch.load(fp)\n",
    "    acc, y_true, y_pred = test(net, device)\n",
    "    heatmap(y_true, y_pred, \"RESNET34P\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/maestro-v3.0.0_modify.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "# Subset for  composer identification\n",
    "# data.drop_duplicates(\"canonical_title\",keep = False, inplace = True)\n",
    "# counts = data[\"canonical_composer\"].value_counts()\n",
    "# selected_composers = counts[counts >= 50].index #24\n",
    "# selected_composers = np.asarray(selected_composers)\n",
    "# selection = pd.DataFrame(columns=data.columns)\n",
    "# for i in selected_composers:\n",
    "#     choices = data[data[\"canonical_composer\"] == i].head(60)\n",
    "#     selection = pd.concat([selection, choices], ignore_index=True)\n",
    "# selection.to_csv(\"data/composer_selection.csv\", index=False)\n",
    "# # Subset for performer identificaion\n",
    "counts = data[\"performer\"].value_counts()\n",
    "selected_performers = counts[counts >= 10].index #24\n",
    "selected_performers = np.asarray(selected_performers)\n",
    "selection = pd.DataFrame(columns=data.columns)\n",
    "for i in selected_performers:\n",
    "    choices = data[data[\"performer\"] == i]\n",
    "    selection = pd.concat([selection, choices], ignore_index=True)\n",
    "selection.to_csv(\"data/performer_selection.csv\")\n",
    "\n",
    "# Johann Sebastian Bach,\"Prelude and Fugue in C sharp major, WTC I, BWV 848\",\n",
    "#train,2011,2011/MIDI-Unprocessed_24_R1_2011_MID--AUDIO_R1-D9_08_Track08_wav.midi,\n",
    "#2011/MIDI-Unprocessed_24_R1_2011_MID--AUDIO_R1-D9_08_Track08_wav.wav,202.54920984400002,\n",
    "#Vivian Lou,Canada,174,386\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa.display\n",
    "# wav, fs = librosa.load(\"/import/c4dm-datasets/maestro-v2.0.0/2011/MIDI-Unprocessed_24_R1_2011_MID--AUDIO_R1-D9_08_Track08_wav.wav\", sr=44100, offset=0, duration=500)\n",
    "# mel = librosa.feature.melspectrogram(wav, \n",
    "#                                     sr=fs, \n",
    "#                                     hop_length=1024,\n",
    "#                                     win_length=2048,\n",
    "#                                     n_fft=2048,\n",
    "#                                     n_mels=64, \n",
    "#                                     fmax =8000)\n",
    "# fig, ax = plt.subplots()\n",
    "# S_dB = librosa.power_to_db(mel, ref=np.max)\n",
    "# img = librosa.display.specshow(S_dB, x_axis='time',\n",
    "#                          y_axis='mel', sr=fs,\n",
    "#                          fmax=8000, ax=ax)\n",
    "# fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "# ax.set(title='Mel-frequency spectrogram')\n",
    "# plt.savefig(\"sample_plot.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ospi",
   "language": "python",
   "name": "ospi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
